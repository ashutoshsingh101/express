Project -- Extarcting information out of medical reports in PDF format.
================================================================================================================================================

Extracting information  from a PDF document is a difficult process. Many libraries are available in different languages for conversion of PDF to text,HTML,XML,image etc.

The problem with most of these libraries is that the inherent structure of the document is lost when the above operations are perfomed to extract the information. This project focuses on preserving the structure of the document while extracting text from the document.



Whole project is divided into three parts--

1. DCM(Data Chunking Model)
2. Image Interpreter
3. OIR(Optical Image recognition)

==============================================================================================================================================
Data Chunking Model -- 

1. Reading and resizing of image is done in this part then the resized image is converted into grayscale image.

2. Calculate average of each row of pixel intensities of grayscale image and make a row vector.

3. Using this row vector detect any horizontal line if it is longer than (width of image)/3. If such a line is found make a primary partition there.

4. More primary partions are made using row vector by checkin presence of a certain number of completely white rows between the lines. This number is represented as PRIMARY_HORIZONTAL_SKIP_PIXEL. Indices of row vector where primary separations are marked are stored in a list named HORIZONTAL_CHUNK_INDEX. 
 
5. Using  HORIZONTAL_CHUNK_INDEX, we access one primary segment at a time and initialize a dictionary INNER_DICT  containing START and END index of that particular segment. For each primary segment calculate average of pixel intensities of each column within that primary segment and store all the averages into column vector.

6. With the column vector we can detect the presence a particular no. of white columns consecutively and if the condition is satisfied the primary segment is divided vertically. This no. is the SECONDARY_VERTICAL_SKIP_PIXEL count. the index in the column vector where the vertical division is made is stored in list named COLUMNS and add to the INNER_DICT.

7. The next step is to further divide the primary segment into rows where no. of white rows is equal to SECONDARY_HORIZONTAL_SKIP_PIXEL. Store those indices of row vector where the secondary divisions were made into a list ROWS and add to INNER_DICT.

8. Repeat steps 5, 6, 7 for each primary segment.Prepare a dictionary DATA_DICT  and add all the INNER_DICTs to it.

==============================================================================================================================================
Optical Image Recognition --

1. Using the DATA_DICT prepare a mutidimentional array with format with the outermost arrays being the pages, inside the page lists there are row lists, which further contains dictionaries containing co-ordinates and text of each cell in that specific row.The co-ordinates are calculated using the ROWS AND COLUMNS lists of each INNER_DICT.

2. The cordinates of cells are used to crop that particular cell out of the image and send it to GOOGLE VISION api for OCR to extract text. The text is stored inside text variable of dictionary of that cell.

3. Final output is a multi-d array with information about the location of text on the image(in turn the PDF) and the text. 

===============================================================================================================================================



